import re
from konlpy.tag import Okt

okt = Okt()


def preprocess_text(text):
    # 소문자 변환
    text = text.lower()

    # 특수 문자 제거 (한글과 알파벳, 공백만 허용)
    text = re.sub(r'[^\w\s가-힣]', '', text)

    # 숫자 제거
    text = re.sub(r'\d+', '', text)

    # 특정 패턴 제거
    patterns = [
        r'원해(요|합니다)?',
        r'구해(요|합니다)?',
        r'찾고 있습니다',
        r'개발자',  # 단어 제거
        r'<[^>]+>',  # HTML 태그
        r'\b[가-힣]{1,2}\b',  # 1~2글자 한글 단어 (예: 고, 한)
        r'요즘',
        r'최근',
        r'많(이|아요|습니다)?',
        r'좋(아합니다|아해요|겠어|겠어요|겠다|습니다|다)?',
        r'사용(합니다|해요)?',
        r'관심',
        r'이슈',
        r'니다',  # '습니다', '니다' 등 패턴 추가
        r'되다',
        r'합니다',
        r'됩니다',
        r'어요',
        r'세요',
        r'나요',
        r'고요',
        r'이고',
        r'라고',
        r'이고요',
        r'무슨',
        r'있습니다',
        r'있어요'
    ]

    # 패턴 길이순 정렬 (길이가 긴 패턴부터)
    patterns.sort(key=len, reverse=True)

    for pattern in patterns:
        text = re.sub(pattern, '', text)

    # 형태소 분석
    tokens = okt.morphs(text)

    KOREAN_STOP_WORDS = {'가', '이', '은', '는', '이', '가', '의', '과', '에서', '하고', '으로', '에', '에게', '로', '다', '하', '들', '을',
                         '를', '에서', '있','없','있습니다', '없습니다', '합니다', '되다', '그', '저', '저희', '우리', '그들', '그것', '어디','이면','적','인',
                         '언제', '입니다', '하는', '걸', '또한', '저희', '지금', '그저', '너무', '어쩌면','있는','사람','습니다ㄴ','ㅂ니다','스타일','그리고','그러나',
                         '이제', '하지만', '또는', '그래서', '더욱', '결국', '게다가', '그러므로', '즉', '때문', '위해', '처럼', '만큼', '따라서', '그렇지만',
                         '무슨', '원해', '구합니다', '찾고', '있습니다', '있어요'}

    # 불용어 제거
    tokens = [word for word in tokens if word not in KOREAN_STOP_WORDS]

    # 특정 접미사 제거 (예: '하고' 제거)
    suffixes_to_remove = ['하고', '한테', '의', '에서', '다', 'ㄴ', '은', '는', '이', '가', '의', '로', '되다', '니다', '어요', '나요', '고요']
    tokens = [word for word in tokens if word not in suffixes_to_remove]

    # 사전 정의된 단어 목록
    predefined_words = [
        '클린코드','멀티모듈','마이웨이','데이터사이언티스트','프론트엔드','백엔드','풀스택','머신러닝',
        '딥러닝','인공지능','데브옵스','클라우드','컨테이너','마이크로서비스','API','데이터베이스',
        '모바일','웹개발','UX디자인','UI디자인','안드로이드','아이오에스','테스트자동화','데이터분석',
        '대규모트래픽','서버리스','리액트','뷰','앵귤러','파이썬','자바스크립트','자바','C언어','C++',
        '고언어','스위프트','코틀린','R언어','SQL','NoSQL','하둡','스파크','카프카','젠킨스',
        '도커','쿠버네티스','AWS','GCP','Azure','서버관리','네트워크보안','사이버보안','기계학습',
        '자연어처리','컴퓨터비전','프로덕트매니저','프로젝트매니저','기술지원','솔루션아키텍트'
    ]

    # 보호된 단어들 복원
    i = 0
    while i < len(tokens):
        # 현재 토큰에서 가능한 합쳐진 단어를 찾기 위한 루프
        j = i + 1
        while j <= len(tokens):
            combined_word = ''.join(tokens[i:j])
            if combined_word in predefined_words:
                tokens = tokens[:i] + [combined_word] + tokens[j:]
                break  # 합쳐졌으므로, i를 다시 설정하고 계속 진행
            j += 1
        i += 1  # 다음 토큰으로 이동

    # 형태소 분석에서 단어 조합
    tokens = [word for word in tokens if len(word) > 1]  # 길이가 1인 단어는 제거

    return ' '.join(tokens)
